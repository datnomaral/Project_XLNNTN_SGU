# HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG - Äá»’ ÃN Dá»ŠCH MÃY ANH-PHÃP

## ğŸ¯ Má»¥c tiÃªu dá»± Ã¡n
XÃ¢y dá»±ng mÃ´ hÃ¬nh **Encoder-Decoder LSTM** vá»›i **context vector cá»‘ Ä‘á»‹nh** Ä‘á»ƒ dá»‹ch tá»« **tiáº¿ng Anh sang tiáº¿ng PhÃ¡p**.

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
Äá»’ ÃN Xá»¬ LÃ NGÃ”N NGá»® Tá»° NHIÃŠN/
â”œâ”€â”€ README.md                    # Tá»•ng quan dá»± Ã¡n
â”œâ”€â”€ QUICK_START.md               # File nÃ y - HÆ°á»›ng dáº«n nhanh
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ main.ipynb                   # â­ NOTEBOOK CHÃNH - Cháº¡y tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i
â”‚
â”œâ”€â”€ src/                         # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py           # Xá»­ lÃ½ dá»¯ liá»‡u, vocab, DataLoader
â”‚   â”œâ”€â”€ model.py                 # Encoder, Decoder, Seq2Seq
â”‚   â”œâ”€â”€ train.py                 # Training loop, early stopping
â”‚   â”œâ”€â”€ evaluate.py              # BLEU score, visualization
â”‚   â””â”€â”€ translate.py             # Greedy/Beam decoding
â”‚
â”œâ”€â”€ data/                        # (Sáº½ tá»± Ä‘á»™ng táº¡o khi download dataset)
â”‚   â””â”€â”€ multi30k/
â”‚
â”œâ”€â”€ checkpoints/                 # (Tá»± Ä‘á»™ng táº¡o khi training)
â”‚   â””â”€â”€ best_model.pth          # â­ Model tá»‘t nháº¥t (Ná»˜P BÃ€I)
â”‚
â”œâ”€â”€ results/                     # (Tá»± Ä‘á»™ng táº¡o khi cháº¡y)
â”‚   â”œâ”€â”€ training_history.json   # Lá»‹ch sá»­ train/val loss
â”‚   â”œâ”€â”€ training_history.png    # Biá»ƒu Ä‘á»“ loss
â”‚   â”œâ”€â”€ bleu_scores.json        # BLEU scores
â”‚   â”œâ”€â”€ bleu_scores.png         # Biá»ƒu Ä‘á»“ BLEU
â”‚   â””â”€â”€ error_analysis.json     # PhÃ¢n tÃ­ch lá»—i
â”‚
â””â”€â”€ report/                      # BÃ¡o cÃ¡o
    â”œâ”€â”€ REPORT_GUIDE.md         # HÆ°á»›ng dáº«n viáº¿t bÃ¡o cÃ¡o PDF
    â””â”€â”€ report.pdf              # â­ BÃO CÃO CUá»I CÃ™NG (Ná»˜P BÃ€I)
```

---

## ğŸš€ CÃCH CHáº Y Dá»° ÃN

### PhÆ°Æ¡ng phÃ¡p 1: Cháº¡y trÃªn Google Colab (Khuyáº¿n nghá»‹)

1. **Upload toÃ n bá»™ thÆ° má»¥c lÃªn Google Drive**
   ```
   My Drive/Äá»’ ÃN Xá»¬ LÃ NGÃ”N NGá»® Tá»° NHIÃŠN/
   ```

2. **Má»Ÿ `main.ipynb` báº±ng Google Colab**
   - Click chuá»™t pháº£i vÃ o file â†’ "Open with Google Colaboratory"

3. **Mount Google Drive** (thÃªm cell Ä‘áº§u tiÃªn):
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   %cd /content/drive/MyDrive/Äá»’ ÃN Xá»¬ LÃ NGÃ”N NGá»® Tá»° NHIÃŠN
   ```

4. **Cháº¡y toÃ n bá»™ notebook** (Runtime â†’ Run all)
   - Thá»i gian cháº¡y: ~30-60 phÃºt (tÃ¹y GPU)

---

### PhÆ°Æ¡ng phÃ¡p 2: Cháº¡y trÃªn mÃ¡y local (Windows)

#### BÆ°á»›c 1: CÃ i Ä‘áº·t Python
- YÃªu cáº§u: Python 3.8 trá»Ÿ lÃªn
- Download: https://www.python.org/downloads/

#### BÆ°á»›c 2: Táº¡o virtual environment (khuyáº¿n nghá»‹)
```powershell
cd "D:\Äá»’ ÃN Xá»¬ LÃ NGÃ”N NGá»® Tá»° NHIÃŠN"
python -m venv venv
.\venv\Scripts\activate
```

#### BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies
```powershell
pip install -r requirements.txt
```

#### BÆ°á»›c 4: Download spaCy models
```powershell
python -m spacy download en_core_web_sm
python -m spacy download fr_core_news_sm
```

#### BÆ°á»›c 5: Cháº¡y Jupyter Notebook
```powershell
jupyter notebook main.ipynb
```

---

## ğŸ“Š Káº¿t quáº£ ká»³ vá»ng

### Sau khi cháº¡y xong `main.ipynb`:

âœ… **Checkpoints:**
- `checkpoints/best_model.pth` (~XX MB)

âœ… **Results:**
- `results/training_history.json` - Lá»‹ch sá»­ loss
- `results/training_history.png` - Biá»ƒu Ä‘á»“ train/val loss
- `results/bleu_scores.json` - BLEU-1, BLEU-2, BLEU-3, BLEU-4
- `results/bleu_scores.png` - Biá»ƒu Ä‘á»“ BLEU
- `results/error_analysis.json` - 5 vÃ­ dá»¥ lá»—i dá»‹ch + phÃ¢n loáº¡i

âœ… **Console output:**
- Model architecture
- Training progress (progress bars)
- Best validation loss
- BLEU scores
- 5 translation examples

---

## ğŸ“ THANG ÄIá»‚M (10 Ä‘iá»ƒm)

| TiÃªu chÃ­ | Äiá»ƒm | Kiá»ƒm tra |
|----------|------|----------|
| âœ… Triá»ƒn khai Encoder-Decoder LSTM Ä‘Ãºng | 3.0 | `src/model.py` |
| âœ… Xá»­ lÃ½ dá»¯ liá»‡u, DataLoader, padding/packing | 2.0 | `src/data_utils.py` |
| âœ… Huáº¥n luyá»‡n á»•n Ä‘á»‹nh, early stopping, checkpoint | 1.5 | `src/train.py` + `checkpoints/` |
| âœ… HÃ m `translate()` hoáº¡t Ä‘á»™ng vá»›i cÃ¢u má»›i | 1.0 | `src/translate.py` |
| âœ… ÄÃ¡nh giÃ¡ BLEU score + biá»ƒu Ä‘á»“ loss | 1.0 | `src/evaluate.py` + `results/` |
| âœ… PhÃ¢n tÃ­ch 5 vÃ­ dá»¥ lá»—i + Ä‘á» xuáº¥t | 1.0 | `results/error_analysis.json` |
| âœ… Cháº¥t lÆ°á»£ng code (sáº¡ch, comment, cáº¥u trÃºc) | 0.5 | ToÃ n bá»™ `src/` |
| âœ… BÃ¡o cÃ¡o PDF Ä‘áº§y Ä‘á»§ | 0.5 | `report/report.pdf` |
| ğŸŒŸ **Äiá»ƒm cá»™ng (má»Ÿ rá»™ng)** | 1.0 | Attention, Beam search, BPE, ... |

---

## ğŸ“ CHECKLIST Ná»˜P BÃ€I (Háº¡n: 14/12/2025 23:59)

### â­ Báº®T BUá»˜C Ná»˜P:

- [ ] **1. MÃ£ nguá»“n (Jupyter Notebook hoáº·c .py)**
  - `main.ipynb` (cháº¡y Ä‘Æ°á»£c tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i)
  - Hoáº·c: ToÃ n bá»™ thÆ° má»¥c `src/` + `main.ipynb`
  - CÃ³ comment rÃµ rÃ ng

- [ ] **2. BÃ¡o cÃ¡o PDF**
  - File: `report.pdf`
  - Ná»™i dung: SÆ¡ Ä‘á»“ kiáº¿n trÃºc, biá»ƒu Ä‘á»“, BLEU score, 5 vÃ­ dá»¥ lá»—i, Ä‘á» xuáº¥t cáº£i tiáº¿n
  - TrÃ­ch dáº«n tÃ i liá»‡u tham kháº£o

- [ ] **3. Checkpoint mÃ´ hÃ¬nh**
  - File: `best_model.pth` (hoáº·c .pt, .ckpt)
  - Pháº£i load Ä‘Æ°á»£c vÃ  cháº¡y inference

### âœ… KIá»‚M TRA CUá»I:

- [ ] Notebook cháº¡y Ä‘Æ°á»£c trÃªn Google Colab hoáº·c mÃ¡y local
- [ ] KhÃ´ng sao chÃ©p code (tá»± viáº¿t hoáº·c hiá»ƒu rÃµ)
- [ ] HÃ m `translate(sentence: str) -> str` hoáº¡t Ä‘á»™ng Ä‘Ãºng
- [ ] BLEU score Ä‘Æ°á»£c tÃ­nh trÃªn **test set** (khÃ´ng pháº£i train/val)
- [ ] BÃ¡o cÃ¡o cÃ³ Ä‘áº§y Ä‘á»§ biá»ƒu Ä‘á»“ vÃ  phÃ¢n tÃ­ch

---

## ğŸ› ï¸ TROUBLESHOOTING (Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p)

### âŒ Lá»—i: "No module named 'torchtext'"
```powershell
pip install torchtext
```

### âŒ Lá»—i: "Can't find model 'en_core_web_sm'"
```powershell
python -m spacy download en_core_web_sm
python -m spacy download fr_core_news_sm
```

### âŒ Lá»—i: "CUDA out of memory"
**Giáº£i phÃ¡p:**
1. Giáº£m batch size: `BATCH_SIZE = 32` hoáº·c `16`
2. Giáº£m hidden size: `HIDDEN_SIZE = 256`
3. Cháº¡y trÃªn CPU: `device = torch.device('cpu')`

### âŒ Lá»—i: "Multi30K dataset download failed"
**Giáº£i phÃ¡p:**
1. Download thá»§ cÃ´ng tá»«: https://github.com/multi30k/dataset
2. Äáº·t vÃ o thÆ° má»¥c `data/multi30k/`
3. Uncomment code load tá»« file local trong notebook

### âŒ Model khÃ´ng há»™i tá»¥ (loss khÃ´ng giáº£m)
**Kiá»ƒm tra:**
1. Learning rate quÃ¡ lá»›n/nhá» â†’ Thá»­ `lr=0.0001` hoáº·c `0.001`
2. Gradient exploding â†’ Kiá»ƒm tra `clip=1.0`
3. Data preprocessing sai â†’ In ra vÃ i sample kiá»ƒm tra

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

### Papers:
1. **Sutskever et al. (2014)** - Sequence to Sequence Learning with Neural Networks
   - https://arxiv.org/abs/1409.3215

2. **Cho et al. (2014)** - Learning Phrase Representations using RNN Encoder-Decoder
   - https://arxiv.org/abs/1406.1078

3. **Bahdanau et al. (2014)** - Neural Machine Translation by Jointly Learning to Align and Translate (Attention)
   - https://arxiv.org/abs/1409.0473

### Documentation:
- PyTorch LSTM: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html
- torchtext: https://pytorch.org/text/stable/index.html
- spaCy: https://spacy.io/usage
- NLTK BLEU: https://www.nltk.org/api/nltk.translate.html

### Dataset:
- Multi30K: https://github.com/multi30k/dataset
- WMT 2014: http://www.statmt.org/wmt14/translation-task.html

---

## ğŸ’¡ Máº¸O Äáº T ÄIá»‚M CAO

### 1. Code cháº¥t lÆ°á»£ng (0.5 Ä‘iá»ƒm)
- âœ… Comment Ä‘áº§y Ä‘á»§, rÃµ rÃ ng
- âœ… Äáº·t tÃªn biáº¿n cÃ³ Ã½ nghÄ©a
- âœ… TÃ¡ch module rÃµ rÃ ng (data, model, train, evaluate)
- âœ… CÃ³ docstring cho functions/classes

### 2. BÃ¡o cÃ¡o chuyÃªn nghiá»‡p (0.5 Ä‘iá»ƒm)
- âœ… SÆ¡ Ä‘á»“ kiáº¿n trÃºc Ä‘áº¹p (váº½ báº±ng draw.io, PowerPoint)
- âœ… Biá»ƒu Ä‘á»“ rÃµ nÃ©t, cÃ³ caption
- âœ… PhÃ¢n tÃ­ch sÃ¢u sáº¯c (khÃ´ng chá»‰ mÃ´ táº£)
- âœ… TrÃ­ch dáº«n chuáº©n (IEEE, APA)

### 3. Äiá»ƒm cá»™ng (1.0 Ä‘iá»ƒm)
**Lá»±a chá»n 1-2 trong cÃ¡c cáº£i tiáº¿n sau:**

#### ğŸŒŸ ThÃªm Attention Mechanism (+0.5 Ä‘iá»ƒm)
- Bahdanau attention hoáº·c Luong attention
- So sÃ¡nh vá»›i baseline (no attention)

#### ğŸŒŸ Beam Search (+0.3 Ä‘iá»ƒm)
- Implement beam search vá»›i beam_size = 3, 5, 10
- So sÃ¡nh BLEU vá»›i greedy decoding

#### ğŸŒŸ Subword Tokenization (BPE) (+0.3 Ä‘iá»ƒm)
- Sá»­ dá»¥ng `sentencepiece` hoáº·c `subword-nmt`
- Giáº£m OOV, cáº£i thiá»‡n BLEU

#### ğŸŒŸ Dataset lá»›n hÆ¡n (WMT 2014) (+0.4 Ä‘iá»ƒm)
- Train trÃªn ~1 triá»‡u cÃ¢u
- So sÃ¡nh vá»›i Multi30K

---

## ğŸ¯ LUá»’NG CÃ”NG VIá»†C KHUYáº¾N NGHá»Š

### Tuáº§n 1-2: Chuáº©n bá»‹
- [ ] Äá»c hiá»ƒu Ä‘á» tÃ i
- [ ] NghiÃªn cá»©u Encoder-Decoder LSTM
- [ ] Thiáº¿t láº­p mÃ´i trÆ°á»ng (Python, PyTorch, spaCy)

### Tuáº§n 3-4: Coding
- [ ] Viáº¿t `data_utils.py` â†’ Test vá»›i vÃ i samples
- [ ] Viáº¿t `model.py` â†’ Kiá»ƒm tra forward pass
- [ ] Viáº¿t `train.py` â†’ Cháº¡y 1-2 epochs thá»­ nghiá»‡m
- [ ] Viáº¿t `evaluate.py` vÃ  `translate.py`

### Tuáº§n 5: Training & Evaluation
- [ ] Train mÃ´ hÃ¬nh hoÃ n chá»‰nh (10-20 epochs)
- [ ] ÄÃ¡nh giÃ¡ BLEU score
- [ ] PhÃ¢n tÃ­ch lá»—i
- [ ] Test hÃ m translate()

### Tuáº§n 6: BÃ¡o cÃ¡o
- [ ] Váº½ sÆ¡ Ä‘á»“ kiáº¿n trÃºc
- [ ] Viáº¿t bÃ¡o cÃ¡o PDF theo template
- [ ] Kiá»ƒm tra láº¡i code, checkpoint
- [ ] Ná»™p bÃ i trÆ°á»›c deadline

---

## ğŸ“§ Há»– TRá»¢

Náº¿u gáº·p váº¥n Ä‘á»:
1. **Äá»c láº¡i REPORT_GUIDE.md** - CÃ³ hÆ°á»›ng dáº«n chi tiáº¿t
2. **Google error message** - Háº§u háº¿t lá»—i PyTorch Ä‘Ã£ cÃ³ trÃªn StackOverflow
3. **Há»i giáº£ng viÃªn** - Email hoáº·c trong giá» lab

---

## âœ¨ CHÃšC Báº N THÃ€NH CÃ”NG!

**Háº¡n ná»™p: 14/12/2025 (23:59)**

Nhá»› kiá»ƒm tra ká»¹ trÆ°á»›c khi ná»™p:
- âœ… Notebook cháº¡y Ä‘Æ°á»£c
- âœ… Checkpoint tá»“n táº¡i vÃ  load Ä‘Æ°á»£c
- âœ… BÃ¡o cÃ¡o PDF Ä‘áº§y Ä‘á»§
- âœ… Code sáº¡ch, cÃ³ comment

**Good luck!** ğŸš€

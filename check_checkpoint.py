"""
Script kiá»ƒm tra ná»™i dung file best_model.pth
"""
import torch
import os

checkpoint_path = 'checkpoints/best_model.pth'

# Kiá»ƒm tra file tá»“n táº¡i
if not os.path.exists(checkpoint_path):
    print(f"âŒ File khÃ´ng tá»“n táº¡i: {checkpoint_path}")
    exit(1)

# Load checkpoint
print("Äang load checkpoint...")
checkpoint = torch.load(checkpoint_path, map_location='cpu')

print("\n" + "="*60)
print("THÃ”NG TIN CHECKPOINT")
print("="*60)

# Hiá»ƒn thá»‹ thÃ´ng tin
print(f"\nğŸ“ File: {checkpoint_path}")
print(f"ğŸ“¦ Size: {os.path.getsize(checkpoint_path) / (1024*1024):.2f} MB")

print(f"\nğŸ”‘ Keys trong checkpoint:")
for key in checkpoint.keys():
    print(f"   - {key}")

# Chi tiáº¿t tá»«ng key
print(f"\nğŸ“Š Chi tiáº¿t:")
if 'epoch' in checkpoint:
    print(f"   Epoch:      {checkpoint['epoch']}")
if 'train_loss' in checkpoint:
    print(f"   Train Loss: {checkpoint['train_loss']:.4f}")
if 'val_loss' in checkpoint:
    print(f"   Val Loss:   {checkpoint['val_loss']:.4f}")

if 'model_state_dict' in checkpoint:
    state_dict = checkpoint['model_state_dict']
    print(f"\nğŸ§  Model State Dict: {len(state_dict)} layers")
    print("   CÃ¡c layer chÃ­nh:")
    for i, (name, param) in enumerate(state_dict.items()):
        if i < 10:  # Chá»‰ hiá»ƒn thá»‹ 10 layer Ä‘áº§u
            print(f"      {name}: {param.shape}")
        elif i == 10:
            print(f"      ... vÃ  {len(state_dict) - 10} layers khÃ¡c")
            break

if 'optimizer_state_dict' in checkpoint:
    print(f"\nâš™ï¸  Optimizer State Dict: CÃ³")

print("\n" + "="*60)
print("âœ… FILE CHECKPOINT Há»¢P Lá»†!")
print("="*60)
